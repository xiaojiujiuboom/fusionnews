import os
import requests
import feedparser
import datetime
import time
import random
import hashlib
import google.generativeai as genai
from bs4 import BeautifulSoup
from time import mktime

# --- é…ç½®éƒ¨åˆ† ---
SERVERCHAN_SENDKEY = os.environ.get("SERVERCHAN_SENDKEY")
GEMINI_API_KEY = os.environ.get("GOOGLE_API_KEY") 

# åˆå§‹åŒ– Gemini
if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash')
    except Exception as e:
        print(f"Gemini é…ç½®å‡ºé”™: {e}")
else:
    print("è­¦å‘Š: æœªé…ç½® GOOGLE_API_KEY")

# --- è¾…åŠ©å‡½æ•°ï¼šå¼ºåŠ›ç½‘é¡µæŠ“å–å™¨ ---
def fetch_url_content(url, source_name):
    print(f"æ­£åœ¨æŠ“å– {source_name} ...")
    try:
        # ä¼ªè£…æˆæ™®é€šæµè§ˆå™¨
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        resp = requests.get(url, headers=headers, timeout=15)
        
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, 'html.parser')
            # ç§»é™¤è„šæœ¬å’Œæ ·å¼ï¼Œåªç•™å¹²è´§
            for script in soup(["script", "style", "nav", "footer", "iframe"]):
                script.extract()
            # æå–æ­£æ–‡ï¼Œé™åˆ¶é•¿åº¦é˜²æ­¢ token æº¢å‡º
            text = soup.get_text(separator='\n', strip=True)[:4000]
            print(f"  -> æˆåŠŸè·å– {len(text)} å­—ç¬¦")
            return f"=== æ¥è‡ª {source_name} çš„æ‹›è˜é¡µé¢æ•°æ® ===\nURL: {url}\né¡µé¢å†…å®¹æ‘˜è¦:\n{text}\n----------------\n"
        else:
            print(f"  -> å¤±è´¥ (çŠ¶æ€ç  {resp.status_code})")
            return f"{source_name} æŠ“å–å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è®¿é—®: {url}\n"
    except Exception as e:
        print(f"  -> æŠ“å–å¼‚å¸¸: {e}")
        return f"{source_name} è¿æ¥è¶…æ—¶ï¼Œè¯·æ‰‹åŠ¨è®¿é—®: {url}\n"

# --- 1. è·å–æ–°é—» (ä¿æŒä¸å˜) ---
def get_fusion_news():
    print("æ­£åœ¨æŠ“å–æ–°é—»...")
    rss_url = "https://news.google.com/rss/search?q=Nuclear+Fusion+when:48h&hl=en-US&gl=US&ceid=US:en"
    try:
        feed = feedparser.parse(rss_url)
        news_items = []
        for entry in feed.entries[:8]: 
            published_time_str = "æœªçŸ¥æ—¶é—´"
            if hasattr(entry, 'published_parsed'):
                dt = datetime.datetime.fromtimestamp(mktime(entry.published_parsed))
                published_time_str = dt.strftime('%Y-%m-%d %H:%M')
            news_items.append(f"- {entry.title} (Time: {published_time_str}) [Link: {entry.link}]")
        return "\n".join(news_items) if news_items else "è¿‡å»48å°æ—¶æ— é‡å¤§æ–°é—»ã€‚"
    except Exception as e:
        return f"æ–°é—»æŠ“å–å¤±è´¥: {e}"

# --- 2. èŒä½é›·è¾¾ (å®šå‘é¶ç‚¹æŠ“å–æ¨¡å¼) ---
def search_internships():
    print("ğŸš€ å¯åŠ¨èŒä½é›·è¾¾ (Targeted Aggregator Mode)...")
    
    # è¿™é‡Œå®šä¹‰äº†ä¸‰ä¸ªå«é‡‘é‡æœ€é«˜çš„èšå˜èŒä½èšåˆé¡µ
    targets = [
        {
            "name": "Fusion Industry Association (FIA)",
            "url": "https://www.fusionindustryassociation.org/about/job-opportunities/"
        },
        {
            "name": "US Fusion Energy Opportunities",
            "url": "https://usfusionenergy.org/opportunities"
        },
        {
            "name": "ITER Jobs",
            "url": "https://www.iter.org/jobs"
        }
    ]
    
    all_content = ""
    for target in targets:
        content = fetch_url_content(target["url"], target["name"])
        all_content += content
        time.sleep(2) # ç¤¼è²Œå»¶æ—¶
        
    return all_content

# --- 3. ç”Ÿæˆæ—¥æŠ¥ ---
def generate_daily_report(news_text, internship_text):
    print("æ­£åœ¨ç”Ÿæˆ AI æ—¥æŠ¥...")
    today_str = datetime.date.today().strftime('%Y-%m-%d')

    fusion_topics = [
        "åŠ³æ£®åˆ¤æ®", "Qå€¼", "MHDä¸ç¨³å®šæ€§", "æ‰˜å¡é©¬å…‹", "ä»¿æ˜Ÿå™¨", "ICF",
        "ç¬¬ä¸€å£ææ–™", "é’¨", "åæ»¤å™¨", "æ°šå¢æ®–æ¯”", "ä¸­å­è¾ç…§", "Hæ¨¡å¼", 
        "ELMs", "ITER", "CFS SPARC", "Helion", "General Fusion"
    ]
    date_hash = int(hashlib.sha256(today_str.encode('utf-8')).hexdigest(), 16)
    today_topic = fusion_topics[date_hash % len(fusion_topics)]

    prompt = f"""
    ä½ æ˜¯ä¸€ä½**æ ¸èšå˜æƒ…æŠ¥å±€ç‰¹å·¥**ã€‚è¯·ç”Ÿæˆ {today_str} çš„æ—¥æŠ¥ã€‚
    
    ---
    ### 1. News Data
    {news_text}
    
    ### 2. Job Market Intel (Raw Scraped Data)
    *(è¿™æ˜¯ç›´æ¥ä» FIAã€ITER ç­‰å®˜ç½‘æŠ“å–çš„ç½‘é¡µæ­£æ–‡æ–‡æœ¬ã€‚)*
    {internship_text}
    
    ### 3. Topic: {today_topic}
    
    ---
    ### è¾“å‡ºè¦æ±‚ (Markdown)
    
    # âš›ï¸ èšå˜æƒ…æŠ¥å±€ | {today_str}
    
    ## ğŸ“° 1. Fusion Frontiers
    *(ç­›é€‰ 4-5 æ¡æ–°é—»)*
    * **[ä¸­æ–‡æ ‡é¢˜]**
        * ğŸ•’ **Time**: [æ—¶é—´]
        * ğŸš€ **Significance**: [ç‚¹è¯„]
        * ğŸ”— [ç‚¹å‡»é˜…è¯»åŸæ–‡]({'{link}'})
    
    ## ğŸ¯ 2. Career Radar (å®˜ç½‘ç›´è¿)
    *(æŒ‡ä»¤ï¼šè¯·åˆ†ææŠ“å–åˆ°çš„ç½‘é¡µæ­£æ–‡ã€‚å‘Šè¯‰ç”¨æˆ·è¿™äº›é¡µé¢ä¸Šç›®å‰ä¸»è¦åœ¨æ‹›å“ªäº›ç±»å‹çš„å²—ä½ï¼Ÿæœ‰æ²¡æœ‰æåˆ°å…·ä½“çš„å…¬å¸åå­—ï¼Ÿ)*
    *(æ³¨æ„ï¼šå¦‚æœç½‘é¡µæ­£æ–‡å¤ªä¹±ï¼Œè¯·åªæå–æœ€æ ¸å¿ƒçš„å²—ä½å…³é”®è¯ï¼Œå¦‚ 'Plasma Physicist', 'Intern', 'Engineer' ç­‰ã€‚)*
    
    * ğŸ¢ **Fusion Industry Association (FIA)**
        * ğŸ“ **æƒ…æŠ¥**: [æ ¹æ®æŠ“å–å†…å®¹ï¼Œæ€»ç»“FIAé¡µé¢ä¸Šåˆ—å‡ºçš„æœ€æ–°æœºä¼šç±»å‹]
        * ğŸ”— [ç‚¹å‡»ç›´è¾¾æ±‡æ€»é¡µ](https://www.fusionindustryassociation.org/about/job-opportunities/)
        
    * ğŸ¢ **US Fusion Energy**
        * ğŸ“ **æƒ…æŠ¥**: [æ ¹æ®æŠ“å–å†…å®¹ï¼Œæ€»ç»“ç¾å›½æ–¹é¢çš„æœºä¼š]
        * ğŸ”— [ç‚¹å‡»ç›´è¾¾æ±‡æ€»é¡µ](https://usfusionenergy.org/opportunities)

    * ğŸ¢ **ITER Organization**
        * ğŸ“ **æƒ…æŠ¥**: [æ ¹æ®æŠ“å–å†…å®¹ï¼ŒITERæœ€è¿‘åœ¨æ‹›ä»€ä¹ˆäººï¼Ÿ]
        * ğŸ”— [ç‚¹å‡»ç›´è¾¾å®˜ç½‘](https://www.iter.org/jobs)
    
    ## ğŸ§  3. Deep Dive: {today_topic}
    * **ä»Šæ—¥è¯æ¡ï¼š{today_topic}**
    * **ğŸ§ ç¡¬æ ¸è§£æ**ï¼š[200å­—]
    * **ğŸ äººè¯ç‰ˆ**ï¼š[ç”Ÿæ´»æ¯”å–»ï¼Œ150å­—]
    * **ğŸ¤” ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ**ï¼š[ä¸€å¥è¯]
    
    ---
    *Generated by FusionBot*
    """
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"å°è¯• {attempt+1} å¤±è´¥: {e}")
            time.sleep(5)
            
    return "âš ï¸ ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ API é…é¢ã€‚"

# --- 4. æ¨é€ ---
def send_wechat(content):
    if not SERVERCHAN_SENDKEY:
        return
    url = f"https://sctapi.ftqq.com/{SERVERCHAN_SENDKEY}.send"
    data = {"title": f"âš›ï¸ {datetime.date.today()} èšå˜æƒ…æŠ¥å±€", "desp": content}
    requests.post(url, data=data)

if __name__ == "__main__":
    news = get_fusion_news()
    internships = search_internships()
    report = generate_daily_report(news, internships)
    print(report)
    send_wechat(report)
