import os
import requests
import feedparser
import datetime
import time
import random
import hashlib
import google.generativeai as genai
from time import mktime
# ã€æ ¸å¿ƒåº“ã€‘å¼•å…¥ DuckDuckGoï¼Œæ— éœ€ API Key å³å¯å…¨ç½‘æœç´¢
from duckduckgo_search import DDGS

# --- é…ç½®éƒ¨åˆ† ---
SERVERCHAN_SENDKEY = os.environ.get("SERVERCHAN_SENDKEY")
GEMINI_API_KEY = os.environ.get("GOOGLE_API_KEY") 

# åˆå§‹åŒ– Gemini
# ä½¿ç”¨ 1.5-flash ä»¥ä¿è¯æœ€å¤§ç¨³å®šæ€§ï¼ˆ2.0 é¢„è§ˆç‰ˆç›®å‰å®¹æ˜“é™æµï¼‰
if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        print(f"Gemini é…ç½®å‡ºé”™: {e}")
else:
    print("è­¦å‘Š: æœªé…ç½® GOOGLE_API_KEY")

# --- 1. è·å–æ–°é—» (ä¿æŒ 48h é™åˆ¶) ---
def get_fusion_news():
    print("æ­£åœ¨æŠ“å–æ–°é—»...")
    rss_url = "https://news.google.com/rss/search?q=Nuclear+Fusion+when:48h&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(rss_url)
        news_items = []
        for entry in feed.entries[:8]: 
            published_time_str = "æœªçŸ¥æ—¶é—´"
            if hasattr(entry, 'published_parsed'):
                dt = datetime.datetime.fromtimestamp(mktime(entry.published_parsed))
                published_time_str = dt.strftime('%Y-%m-%d %H:%M')
            
            news_items.append(f"- {entry.title} (Time: {published_time_str}) [Link: {entry.link}]")
            
        return "\n".join(news_items) if news_items else "è¿‡å»48å°æ—¶æ— é‡å¤§æ–°é—»ã€‚"
    except Exception as e:
        return f"æ–°é—»æŠ“å–å¤±è´¥: {e}"

# --- 2. æ™ºèƒ½å…¨ç½‘èŒä½æŒ–æ˜ (èåˆäº† Smart Search + DuckDuckGo) ---
def search_internships():
    print("æ­£åœ¨æ™ºèƒ½æŒ–æ˜èŒä½ä¿¡æ¯...")
    
    # ã€ç­–ç•¥å‡çº§ã€‘å®šä¹‰ä¸€ç»„â€œçŒå¤´çº§â€æœç´¢æŒ‡ä»¤
    # æ¯æ¬¡è¿è¡Œè„šæœ¬æ—¶ï¼Œéšæœºä»è¿™é‡Œé¢é€‰ä¸€ä¸ªå»æœï¼Œè¿™æ ·èƒ½ä¿è¯æ¯å¤©çœ‹åˆ°çš„å²—ä½æ¥æºä¸åŒ
    # æ—¢åŒ…å«é€šç”¨æœç´¢ï¼Œä¹ŸåŒ…å«é’ˆå¯¹ç‰¹å®šå¤§å‚æˆ–ç‰¹å®šè¯­æ°”çš„æœç´¢
    search_strategies = [
        # ç­–ç•¥A: å¯»æ‰¾å¸¦æœ‰â€œæ­£åœ¨æ‹›è˜â€å­—çœ¼çš„é¡µé¢ (æœ€ç²¾å‡†)
        '(nuclear fusion OR plasma physics) "we are hiring" -news',
        # ç­–ç•¥B: å¯»æ‰¾å…·ä½“çš„èŒä½ç©ºç¼ºå…¬å‘Š
        '(nuclear fusion OR plasma physics) "job opening" -linkedin -indeed',
        # ç­–ç•¥C: é’ˆå¯¹å®ä¹ å’Œæ—©æœŸèŒä¸š
        '"fusion energy" ("internship" OR "summer student" OR "thesis") 2025 2026',
        # ç­–ç•¥D: å®šç‚¹çˆ†ç ´ ITER å’Œ CFS (ä¸¤ä¸ªæœ€å¤§çš„å‘)
        'ITER Organization "jobs" OR "vacancies"',
        'Commonwealth Fusion Systems "careers"',
        # ç­–ç•¥E: å®½æ³›çš„èŒä½æœç´¢
        'nuclear fusion engineer jobs remote or onsite'
    ]
    
    # éšæœºé€‰æ‹©ä¸€ä¸ªç­–ç•¥
    query = random.choice(search_strategies)
    print(f"æœ¬æ¬¡é›·è¾¾æ‰«ææŒ‡ä»¤: {query}")

    try:
        # ä½¿ç”¨ DuckDuckGo æœç´¢ï¼Œè·å–å‰ 8 æ¡ç»“æœ (ç»™ AI è¶³å¤Ÿçš„ç´ æ)
        results = DDGS().text(query, max_results=8)
        
        if not results:
            return f"DuckDuckGo æœ¬æ¬¡æ‰«æ ({query}) æœªè¿”å›ç»“æœï¼Œå»ºè®®æ‰‹åŠ¨è®¿é—® LinkedInã€‚"

        processed_jobs = []
        for item in results:
            title = item.get('title', 'No Title')
            link = item.get('href', '#')
            snippet = item.get('body', 'No snippet')
            
            # ç®€å•çš„å…³é”®è¯è¿‡æ»¤ï¼Œå»æ‰æ˜¾è€Œæ˜“è§çš„å¹¿å‘Š
            if "top 10" in title.lower() or "best colleges" in title.lower():
                continue
                
            processed_jobs.append(f"Source: {title}\nLink: {link}\nSnippet: {snippet}\n---")
            
        print(f"æˆåŠŸæŠ“å–åˆ° {len(processed_jobs)} æ¡æ½œåœ¨å²—ä½çº¿ç´¢")
        return "\n".join(processed_jobs)

    except Exception as e:
        print(f"æœç´¢å¼‚å¸¸: {e}")
        return f"èŒä½æ‰«ææ¨¡å—æš‚æ—¶ä¼‘çœ : {e}"

# --- 3. ç”Ÿæˆæ—¥æŠ¥ (è¯¦ç»† Prompt + æ¯æ—¥ä¸€é¢˜) ---
def generate_daily_report(news_text, internship_text):
    print("æ­£åœ¨ç”Ÿæˆ AI æ—¥æŠ¥...")
    today_str = datetime.date.today().strftime('%Y-%m-%d')

    # ã€è¶…çº§æ‰©å……çŸ¥è¯†åº“ã€‘ç¡®ä¿æ¯å¤©ä¸é‡æ · (50+ è¯æ¡)
    fusion_topics = [
        "åŠ³æ£®åˆ¤æ® (Lawson Criterion)", "åº“ä»‘ç¢°æ’ä¸æˆªé¢", "Qå€¼ (Energy Gain)", "ä¸‰é‡ç§¯",
        "ç£æµä½“åŠ¨åŠ›å­¦ (MHD)", "é˜¿å°”èŠ¬æ³¢", "æœ—ç¼ªå°”æ³¢",
        "æ‰˜å¡é©¬å…‹åŸç†", "ä»¿æ˜Ÿå™¨çº¿åœˆè®¾è®¡", "çƒå½¢æ‰˜å¡é©¬å…‹ (ST)", 
        "ååœºç®ç¼© (RFP)", "ç£é•œ", "Z-Pinch", "æƒ¯æ€§çº¦æŸèšå˜ (ICF) ç‚¹ç«",
        "ç¬¬ä¸€å£ææ–™", "é’¨ (Tungsten) çš„åº”ç”¨", "é“ (Beryllium)",
        "åæ»¤å™¨ (Divertor) çƒ­è´Ÿè·", "æ°šå¢æ®–æ¯” (TBR)", "é”‚é“…åŒ…å±‚",
        "ä¸­å­è¾ç…§æŸä¼¤ (DPA)", "é¥æ“ä½œç»´æŠ¤ (Remote Handling)", "ä½æ¸©æ³µæŠ€æœ¯",
        "ä¸­æ€§æŸæ³¨å…¥ (NBI)", "ç¦»å­å›æ—‹å…±æŒ¯åŠ çƒ­ (ICRH)", "ç”µå­å›æ—‹åŠ çƒ­ (ECRH)", "ä½æ‚æ³¢é©±åŠ¨",
        "Hæ¨¡å¼ (High-confinement Mode)", "è¾¹ç¼˜å±€åŸŸæ¨¡ (ELMs)", "é”¯é½¿æŒ¯è¡", 
        "æ–°ç»å…¸è¾“è¿", "é€ƒé€¸ç”µå­", "ç£å²›æ•ˆåº”", "ç­‰ç¦»å­ä½“ç ´è£‚ (Disruption)",
        "ITER ç»„è£…è¿›åº¦", "CFS SPARC", "Helion è„‰å†²ç£èšå˜", 
        "General Fusion", "ä¸­å›½ç¯æµå™¨ä¸‰å· (HL-3)", "EAST", "NIF æ¿€å…‰èšå˜"
    ]
    
    # åŸºäºæ—¥æœŸçš„å“ˆå¸Œé€‰æ‹©ï¼Œä¿è¯å…¨å¤©ä¸€è‡´ï¼Œéš”å¤©å˜æ ·
    date_hash = int(hashlib.sha256(today_str.encode('utf-8')).hexdigest(), 16)
    today_topic_index = date_hash % len(fusion_topics)
    today_topic = fusion_topics[today_topic_index]

    prompt = f"""
    ä½ æ˜¯ä¸€ä½**æ ¸èšå˜æƒ…æŠ¥å±€çš„ç‰¹å·¥**ã€‚è¯·ç”Ÿæˆ {today_str} çš„æ—¥æŠ¥ã€‚
    
    ---
    ### 1. æ–°é—»æ•°æ® (News)
    {news_text}
    
    ### 2. æ‹›è˜çº¿ç´¢ (Raw Job Search Data)
    *(è¿™æ˜¯é€šè¿‡å…¨ç½‘æœç´¢å…³é”®è¯æŠ“å–åˆ°çš„ç»“æœï¼ŒåŒ…å«æ ‡é¢˜å’Œæ‘˜è¦)*
    {internship_text}
    
    ### 3. ä»Šæ—¥é”å®šè¯¾é¢˜: {today_topic}
    *(æ ¹æ®æ—¥æœŸé”å®šï¼Œä¸å¯æ›´æ”¹)*
    
    ---
    ### è¾“å‡ºæ ¼å¼è¦æ±‚ (Markdown)
    
    # âš›ï¸ èšå˜æƒ…æŠ¥å±€ | {today_str}
    
    ## ğŸ“° 1. Fusion Frontiers (æœ€æ–°åŠ¨æ€)
    *(ç­›é€‰ 5 æ¡æœ€è¿‘ 48h çš„æ–°é—»)*
    * **[ä¸­æ–‡æ ‡é¢˜]**
        * ğŸ•’ **Time**: [åŸæ–‡æ—¶é—´]
        * ğŸ“ **Who**: [æœºæ„/å›½å®¶]
        * ğŸš€ **Significance**: [ç‚¹è¯„]
        * ğŸ”— [ç‚¹å‡»é˜…è¯»åŸæ–‡]({'{link}'}) 
    
    ## ğŸ¯ 2. Career Radar (æ™ºèƒ½çŒå¤´åˆ†æ)
    *(æŒ‡ä»¤ï¼šè¯·æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„çŒå¤´ï¼Œä»”ç»†åˆ†æä¸Šé¢çš„â€œæ‹›è˜çº¿ç´¢â€ã€‚)*
    *(ä¸è¦åªå¤åˆ¶ç²˜è´´ï¼è¯·é˜…è¯»æœç´¢ç»“æœçš„Snippet(æ‘˜è¦)ï¼Œå°è¯•æ¨æ–­å‡ºï¼šè¿™æ˜¯å“ªä¸ªæœºæ„ï¼Ÿä»–ä»¬åœ¨æ‰¾ä»€ä¹ˆæ ·çš„äººï¼Ÿ)*
    *(å¦‚æœæœç´¢ç»“æœæ˜¾ç¤ºçš„æ˜¯â€œWe are hiringâ€çš„å…¬å‘Šé¡µï¼Œè¯·é‡ç‚¹æ¨èã€‚)*
    
    * ğŸ” **[èŒä½åç§°/æœºæ„åç§°]**
        * ğŸ“ **å²—ä½æƒ…æŠ¥**: [æ ¹æ®æ‘˜è¦æ¨æ–­ï¼šè¿™æ˜¯å…¨èŒ/å®ä¹ ï¼Ÿæ¶‰åŠç‰©ç†/å·¥ç¨‹/ä»¿çœŸï¼Ÿ]
        * ğŸ› ï¸ **å…³é”®è¦æ±‚**: [å¦‚æœæ‘˜è¦é‡Œæåˆ°äº†Python, PhD, CADç­‰å…³é”®è¯ï¼Œè¯·åˆ—å‡ºï¼›å¦‚æœæ²¡æœ‰ï¼Œå†™â€œå»ºè®®ç‚¹å‡»è¯¦æƒ…æŸ¥çœ‹â€]
        * ğŸ”— [ç‚¹å‡»ç›´è¾¾]({'{link}'})
    
    ## ğŸ§  3. Deep Dive: {today_topic}
    *(ä»Šå¤©å¿…é¡»è®²è¿™ä¸ªï¼)*
    * **ä»Šæ—¥è¯æ¡ï¼š{today_topic}**
    * **ğŸ§ ç¡¬æ ¸è§£æ**ï¼š
        [200å­—ä¸“ä¸šè§£é‡Šï¼Œå¯ä»¥ä½¿ç”¨ç‰©ç†æœ¯è¯­]
    * **ğŸ äººè¯ç‰ˆ**ï¼š
        [**å¿…é¡»ä½¿ç”¨ç”Ÿæ´»ä¸­çš„æ¯”å–»** (å¦‚åšé¥­ã€äº¤é€šã€æ°”çƒç­‰) æ¥è§£é‡Šä¸Šé¢çš„æ¦‚å¿µï¼Œè®©å°ç™½ä¹Ÿèƒ½æ‡‚ã€‚150å­—]
    * **ğŸ¤” ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ**ï¼š
        [ä¸€å¥è¯æ€»ç»“å®ƒåœ¨èšå˜å‘ç”µä¸­çš„åœ°ä½]
    
    ---
    *Generated by FusionBot Â· Topic Index: {today_topic_index}*
    """
    
    # é‡è¯•æœºåˆ¶
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"å°è¯• {attempt+1} å¤±è´¥: {e}")
            time.sleep(5)
            
    return "âš ï¸ ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ API é…é¢ã€‚"

# --- 4. æ¨é€ ---
def send_wechat(content):
    if not SERVERCHAN_SENDKEY:
        return
    url = f"https://sctapi.ftqq.com/{SERVERCHAN_SENDKEY}.send"
    data = {"title": f"âš›ï¸ {datetime.date.today()} èšå˜æƒ…æŠ¥å±€", "desp": content}
    requests.post(url, data=data)

if __name__ == "__main__":
    news = get_fusion_news()
    internships = search_internships()
    report = generate_daily_report(news, internships)
    print(report)
    send_wechat(report)
